{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed198e5-445f-44b5-aad5-1ae37e70c50c",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The purpose of this notebook is to create a data hypercube from the GIPL model outputs for multiple permafrost variables (mean annual ground temperature, talik thickness, depth of permafrost base, and depth of top of permafrost) for the Alaska (i.e., CRREL) spatial domain (Aleutians not included). We know from our exploratory data analysis (EDA) that the processing work is mostly of the metadata variety: standardizing filenames, and then also establishing a cohesive spatial reference and NoData value for every GeoTIFF.\n",
    "\n",
    "There are 6000 2471 X 1941 GeoTIFFs with a 1 km spatial resolution distributed equally across the following climate model + emissions scenario combinations: \n",
    "```\n",
    "├── 5Models_45\n",
    "├── 5Models_85\n",
    "├── GFDL_45\n",
    "├── GFDL_85\n",
    "├── NCAR_45\n",
    "└── NCAR_85\n",
    "```\n",
    "\n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "The flow here is as follows:\n",
    "\n",
    " 0. Set up directories and configure data fetch and output archival.\n",
    " 1. Fetch data if needed, and verify all the data is in place.\n",
    " 2. Extract - decompress the data if needed, and verify all files are in place.\n",
    " 3. Specify Output Parameters: File naming convention, raster creation profile\n",
    " 4. Create a new dataset with corrected metadata and NoData values.\n",
    " 5. Archive the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c8b3c-8069-4cab-bc40-7667aae73474",
   "metadata": {},
   "source": [
    "## 0 - Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32c654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import rasterio as rio\n",
    "import re\n",
    "import numpy as np\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import random\n",
    "import tqdm\n",
    "#from multiprocessing import Pool\n",
    "from multiprocess import Pool\n",
    "from pyproj.crs import CRS\n",
    "from pathlib import Path\n",
    "from rasterio import Affine\n",
    "\n",
    "# general config\n",
    "COPY_SOURCE = False\n",
    "COPY_OUTPUTS_TO_ARCHIVE = False\n",
    "os.environ[\"NCORES\"] = \"24\"\n",
    "\n",
    "# directory config\n",
    "os.environ[\"ORIGINAL_SRC_DIR\"] = \"/atlas_scratch/ssmarchenko/ssmarchenko_home/2022_CRREL_proj/\"\n",
    "os.environ[\"PROJECT_DIR\"] = \"/atlas_scratch/cparr4/new_gipl_eda_marchenko_revision/\"\n",
    "os.environ[\"DST_DIR\"] = \"/atlas_scratch/cparr4/new_gipl_eda_marchenko_revision/2022_CRREL_proj/\"\n",
    "os.environ[\"EXTRACT_DIR\"] = \"/atlas_scratch/cparr4/new_gipl_eda_marchenko_revision/2022_CRREL_proj/extracted/\"\n",
    "os.environ[\"OUTPUT_DIR\"] = \"/atlas_scratch/cparr4/new_gipl_eda_marchenko_revision/crrel_gipl_outputs/\"\n",
    "os.environ[\"ARCHIVE_DIR\"] = \"/workspace/Shared/Tech_Projects/Arctic_EDS/project_data/rasdaman_datasets/crrel_gipl_outputs/\"\n",
    "\n",
    "# set the environment variables and create directories and Path objects\n",
    "gipl_src_path = Path(os.environ[\"ORIGINAL_SRC_DIR\"])\n",
    "\n",
    "gipl_dst_path = Path(os.environ[\"DST_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "gipl_dst_path = Path(os.environ[\"DST_DIR\"])\n",
    "\n",
    "extract_path = Path(os.environ[\"EXTRACT_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "extract_path = Path(os.environ[\"EXTRACT_DIR\"])\n",
    "\n",
    "output_path = Path(os.environ[\"OUTPUT_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "output_path = Path(os.environ[\"OUTPUT_DIR\"])\n",
    "\n",
    "archive_path = Path(os.environ[\"ARCHIVE_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "archive_path = Path(os.environ[\"ARCHIVE_DIR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41e946-56ac-440f-bf7a-915899eaca90",
   "metadata": {},
   "source": [
    "## 1 - Fetch\n",
    "\n",
    "We don't need to download external data - these are on our file system courtesy of Sergey Marchenko and the data were intially fetched via\n",
    "\n",
    "```shell\n",
    "cp -r /atlas_scratch/ssmarchenko/ssmarchenko_home/2022_CRREL_proj /atlas_scratch/cparr4/new_gipl_eda_marchenko_revision\n",
    "````\n",
    "but we can include a fetch function to grab data if we need it. These source data (about 58 GB) are compressed `.zip` archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d1da43-3df2-457a-81dd-7411b38cc8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T20:51:07.633531Z",
     "start_time": "2022-01-18T20:51:06.832808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Step 1 (Fetch Data)...\n",
      "\n",
      "66 .zip files are currently located at /atlas_scratch/ssmarchenko/ssmarchenko_home/2022_CRREL_proj.\n",
      "\n",
      "No files were copied from the source directory to the project directory.\n",
      "\n",
      "66 .zip files are currently located at /atlas_scratch/cparr4/new_gipl_eda_marchenko_revision/2022_CRREL_proj.\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing Step 1 (Fetch Data)...\\n\")\n",
    "\n",
    "fps = [x for x in gipl_src_path.rglob(\"*.zip\")]\n",
    "print(f\"{len(fps)} .zip files are currently located at {gipl_src_path}.\")\n",
    "\n",
    "\n",
    "if COPY_SOURCE:\n",
    "    new_fps = [gipl_dst_path / ''.join(x.name) for x in fps]\n",
    "    print(f\"Copying {len(new_fps)} .zip files to {gipl_dst_path}\")\n",
    "    for src, dst in zip(fps, new_fps):\n",
    "        shutil.copy(src, dst)\n",
    "else:\n",
    "    print(\"\\nNo files were copied from the source directory to the project directory.\\n\")\n",
    "    \n",
    "zip_fps = sorted([x for x in gipl_dst_path.rglob(\"*.zip\")])\n",
    "print(f\"{len(zip_fps)} .zip files are currently located at {gipl_dst_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51951a1",
   "metadata": {},
   "source": [
    "## 2 - Extracting\n",
    "\n",
    "There is quite a bit of data to extract. I recommend skipping this step while testing if possible, i.e. just use `cparr4`'s scratch directory or ask around to see if anyone has it stashed. If you do need to extract, you can use this command in a notebook cell to do a find-unzip on all the compressed data. Or, just fire this off in your local shell, minus the bang(!).\n",
    "\n",
    "```shell\n",
    "!find $DST_DIR -name '*.zip' -exec unzip -q -d $EXTRACT_DIR {} \\;\n",
    "```\n",
    "\n",
    "That command will produce a flat directory of the **6000 GeoTIFFs** that are compressed within the source `.zip` files. These data are 245 GB on disk once extracted.\n",
    "\n",
    "We'll do a quick validation of the file paths to make sure all the GeoTiffs are in place. We know from the EDA that there are some file naming inconsistencies, so we'll do a coarse check just on the basis of model-scenario combinations and not worry about variables for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b325e376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6000 GeoTIFFs to process.\n"
     ]
    }
   ],
   "source": [
    "fps = [x for x in extract_path.rglob(\"*.tif\")]\n",
    "rcp45_fps = [x for x in fps if \"rcp45\" in x.name.lower()]\n",
    "rcp85_fps = [x for x in fps if \"rcp85\" in x.name.lower()]\n",
    "\n",
    "gfdl_rcp45_fps = [x for x in rcp45_fps if \"gfdl\" in x.name.lower()]\n",
    "ncar_rcp45_fps = [x for x in rcp45_fps if \"ncar\" in x.name.lower()]\n",
    "fivemodel_rcp45_fps = [x for x in rcp45_fps if \"5mod\" in x.name.lower()]\n",
    "\n",
    "gfdl_rcp85_fps = [x for x in rcp85_fps if \"gfdl\" in x.name.lower()]\n",
    "ncar_rcp85_fps = [x for x in rcp85_fps if \"ncar\" in x.name.lower()]\n",
    "fivemodel_rcp85_fps = [x for x in rcp45_fps if \"5mod\" in x.name.lower()]\n",
    "\n",
    "# check equal number of geotiffs across the different models and scenarios\n",
    "assert len(rcp45_fps) == len(rcp85_fps), f\"Each scenario does not have the sname number of files. RCP 4.5 has {len(rcp45_fps)} GeoTIFFs, but RCP 8.5 has {len(rcp85_fps)}.\"\n",
    "assert len(gfdl_rcp85_fps) == len(gfdl_rcp85_fps) == len(fivemodel_rcp85_fps), \"Number of files per model unequal for RCP 8.5!\"\n",
    "assert len(gfdl_rcp45_fps) == len(gfdl_rcp45_fps) == len(fivemodel_rcp45_fps), \"Number of files per model unequal for RCP 4.5!\"\n",
    "assert len(gfdl_rcp45_fps) == len(gfdl_rcp45_fps) == len(fivemodel_rcp45_fps) == len(gfdl_rcp85_fps) == len(gfdl_rcp85_fps) == len(fivemodel_rcp85_fps)\n",
    "\n",
    "print(f\"There are {len(fps)} GeoTIFFs to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952a861-cca7-4309-af88-c832bb79ade0",
   "metadata": {},
   "source": [
    "## 3 - Specify Output Parameters\n",
    "### 3.1 File Naming: CCCC (Create Consistent Cohesive Convention)\n",
    "\n",
    "We've already segmented the 6000 GeoTIFFs by model and scenario combination. The dataset has ten variables, so we need a convention that reads something like `prefix_model_scenario_variable_year.tif`. We'll probably need regular expressions to extract the year and variable from the existing file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778a67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_year(fp):\n",
    "    \"\"\"Fetch a single year (YYYY) from a file name.\"\"\"\n",
    "    year = re.match(r'.*([1-3][0-9]{3})', fp).group(1)\n",
    "    return year\n",
    "\n",
    "\n",
    "def get_re_depth(fp):\n",
    "    \"\"\"Fetch depth from a file name for mean annual ground temperature (magt) variables.\"\"\"\n",
    "    try:\n",
    "        depth = re.match(r'.*(0.5|1|2|3|4)m_', fp).group(1)\n",
    "    except:\n",
    "        depth = \"5\"\n",
    "    return depth\n",
    "\n",
    "\n",
    "def get_re_permafrost_var(fp):\n",
    "    \"\"\"Fetch the permafrost variable from a file name.\"\"\"\n",
    "    if \"magt\" in fp:\n",
    "        if \"surf\" in fp:\n",
    "            depth = \"surface_\"\n",
    "        else:\n",
    "            depth = get_re_depth(fp) + \"m_\"\n",
    "        pf_var = f\"magt{depth}degC_\"\n",
    "    elif \"talik\" in fp:\n",
    "        pf_var = \"talikthickness_m_\"\n",
    "    elif \"base\" in fp:\n",
    "        pf_var = \"permafrostbase_m_\"\n",
    "    elif \"top\" in fp:\n",
    "        pf_var = \"permafrosttop_m_\"\n",
    "    \n",
    "    return pf_var\n",
    "\n",
    "\n",
    "def create_new_filename(original_fp, new_filename_prefix):\n",
    "        fp_name = original_fp.name.lower()\n",
    "        new_fname = f\"{new_filename_prefix}{get_re_permafrost_var(fp_name)}{get_re_year(fp_name)}.tif\"\n",
    "        return new_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a8178f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_permafrosttop_m_2091.tif'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our parsing and generation with a few random selections\n",
    "create_new_filename(random.choice(fps), \"test_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482da2e",
   "metadata": {},
   "source": [
    " ### 3.2 Raster Creation Profile\n",
    "\n",
    "We know from our EDA work that there is a slight drift in the Affine transform across all the different raster files. We should probably use the affine transform that that is native to the majority of the model outputs. We'll also want to make sure LZW compression and -9999 no data values are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c235ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_check(directory):\n",
    "    all_meta = []\n",
    "    fps = [x for x in directory.glob(\"*.tif\")]\n",
    "    read_lock = threading.Lock()\n",
    "\n",
    "    def process(fp):\n",
    "        src = rio.open(fp)\n",
    "        with read_lock:\n",
    "            profile = src.profile\n",
    "            all_meta.append(profile)\n",
    "    \n",
    "    # We map the process() function over the list of files\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=int(os.getenv(\"NCORES\"))\n",
    "    ) as executor:\n",
    "        executor.map(process, fps)\n",
    "\n",
    "    return all_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb18b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = metadata_check(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1178d852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.4028234663852886e+38, 'width': 2471, 'height': 1941, 'count': 1, 'crs': CRS.from_epsg(3338), 'transform': Affine(1000.0, 0.0, -979791.7089865601,\n",
       "       0.0, -1000.0, 2375479.7509745434), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example metadata object\n",
    "meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4821bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_c_values = []\n",
    "for j in meta:\n",
    "    tx_c_values.append(j[\"transform\"].c)\n",
    "tx_f_values = []\n",
    "for j in meta:\n",
    "    tx_f_values.append(j[\"transform\"].f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d54c529-2f94-4e0d-80b5-2597618c0dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T20:51:14.410937Z",
     "start_time": "2022-01-18T20:51:14.250005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-979791.70898656, -979791.70898656, -979791.70869206]),\n",
       " array([2000, 2000, 2000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tx_c_values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b59afff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2375479.75097454, 2375479.75097454, 2375479.75138362]),\n",
       " array([2000, 2000, 2000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tx_f_values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ed337b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-979791.709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rounding to three places yields consistent c and f Affine transform values\n",
    "np.unique(np.round(tx_c_values,3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa933223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2375479.751"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.round(tx_f_values,3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f5adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(1000.0, 0.0, -979791.709,\n",
       "       0.0, -1000.0, 2375479.751)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transform = Affine(1000.0, 0.0, np.unique(np.round(tx_c_values,3))[0],\n",
    "                       0.0, -1000.0, np.unique(np.round(tx_f_values,3))[0])\n",
    "new_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4223f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1941]), array([6000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height_values = []\n",
    "for j in meta:\n",
    "    height_values.append(j[\"height\"])\n",
    "np.unique(height_values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9169ab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2471]), array([6000]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width_values = []\n",
    "for j in meta:\n",
    "    width_values.append(j[\"width\"])\n",
    "np.unique(width_values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ebf2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = CRS(3338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d13e6b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4028234663852886e+38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will fix this in the new raster creation profile\n",
    "meta[0][\"nodata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b64b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"crs\": crs,\n",
    "    \"transform\": new_transform,\n",
    "    \"width\":  meta[0][\"width\"],\n",
    "    \"height\": meta[0][\"height\"],\n",
    "    \"count\": 1,\n",
    "    \"dtype\": np.float32,\n",
    "    \"nodata\": -9999,\n",
    "    \"tiled\": False,\n",
    "    \"compress\": \"lzw\",\n",
    "    \"interleave\": \"band\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24f0c7",
   "metadata": {},
   "source": [
    "## 4 - Make the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14443292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_values(fp):\n",
    "    \n",
    "    with rio.open(fp) as src:\n",
    "        arr_values = src.read(1)\n",
    "    del src\n",
    "    return arr_values\n",
    "\n",
    "\n",
    "def fix_nodata_values(arr):\n",
    "    \n",
    "    arr[arr == meta[0][\"nodata\"]] = -9999\n",
    "    return arr\n",
    "\n",
    "\n",
    "def write_new_geotiff(out_fp, arr):\n",
    "    with rio.open(out_fp, \"w\", **profile) as dst:\n",
    "        dst.write(arr, 1)\n",
    "    del dst\n",
    "    return\n",
    "\n",
    "\n",
    "def run_new_geotiffs(args):\n",
    "    in_fp, out_fp = args\n",
    "    write_new_geotiff(out_fp, fix_nodata_values(get_array_values(in_fp)))\n",
    "    return\n",
    "\n",
    "\n",
    "def make_permafrost_dataset(original_fps, new_filename_prefix):\n",
    "    \n",
    "    args = []\n",
    "    for raster_src in original_fps:\n",
    "        \n",
    "        args.append((\n",
    "            raster_src,\n",
    "            output_path.joinpath(create_new_filename(raster_src, new_filename_prefix)),\n",
    "        ))\n",
    "    with Pool(int(os.getenv(\"NCORES\"))) as pool:\n",
    "        for _ in tqdm.tqdm(\n",
    "            pool.imap_unordered(run_new_geotiffs, args), total=len(args)\n",
    "        ):\n",
    "            pass\n",
    "    del pool\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ad2bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1000/1000 [01:27<00:00, 11.43it/s]\n"
     ]
    }
   ],
   "source": [
    "make_permafrost_dataset(fivemodel_rcp45_fps, \"gipl_5ModelAvg_rcp45_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1afd5bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1000/1000 [00:28<00:00, 35.70it/s]\n"
     ]
    }
   ],
   "source": [
    "make_permafrost_dataset(fivemodel_rcp85_fps, \"gipl_5ModelAvg_rcp85_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b26686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1000/1000 [01:23<00:00, 12.03it/s]\n"
     ]
    }
   ],
   "source": [
    "make_permafrost_dataset(gfdl_rcp85_fps, \"gipl_GFDL-CM3_rcp85_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0c0d5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1000/1000 [01:31<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "make_permafrost_dataset(gfdl_rcp45_fps, \"gipl_GFDL-CM3_rcp45_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1d99ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1000/1000 [00:33<00:00, 29.57it/s]\n"
     ]
    }
   ],
   "source": [
    "make_permafrost_dataset(ncar_rcp45_fps, \"gipl_NCAR-CCSM4_rcp45_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d384187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1000/1000 [01:21<00:00, 12.30it/s]\n"
     ]
    }
   ],
   "source": [
    "make_permafrost_dataset(ncar_rcp85_fps, \"gipl_NCAR-CCSM4_rcp85_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9759055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fps = [x for x in output_path.glob(\"*.tif\")]\n",
    "assert len(output_fps) == 6000, f\"Only {len(output_fps)} GeoTIFFs were created, but 6000 were expected.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a265f68",
   "metadata": {},
   "source": [
    "## 5 - Archive the data\n",
    "\n",
    "Stash the data in the *backed-up-Rasdaman-pot-of-SNAP-gold<sup>TM</sup>* For the Arctic-EDS that's here: `/workspace/Shared/Tech_Projects/Arctic_EDS/project_data/rasdaman_datasets/$ARCHIVE_DIR` and while we expect these GIPL outputs will hit the storefront in a few different ways (ARDAC, etc.) this is a good spot for right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b832d185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files were copied from the project output directory to the archive directory.\n"
     ]
    }
   ],
   "source": [
    "if COPY_OUTPUTS_TO_ARCHIVE:\n",
    "    archive_fps = [archive_path / ''.join(x.name) for x in output_fps]\n",
    "    print(f\"Copying {len(archive_fps)} files to {archive_path}...\")\n",
    "    for src, dst in zip(output_fps, archive_fps):\n",
    "        shutil.copy(src, dst)\n",
    "    assert(len([x for x in archive_path.rglob(\"*.tif\")]) == len(output_fps))\n",
    "else:\n",
    "    print(\"No files were copied from the project output directory to the archive directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f271a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T20:53:57.391083Z",
     "start_time": "2022-01-18T20:53:57.236735Z"
    }
   },
   "source": [
    "# Pipeline Complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3ad2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
